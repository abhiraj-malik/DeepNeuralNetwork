{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fad7be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.12.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.0.3-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.7.1-cp311-cp311-win_amd64.whl (7.6 MB)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post5-py3-none-any.whl\n",
      "Collecting tensorflow-intel==2.12.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.12.0-cp311-cp311-win_amd64.whl (272.9 MB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached h5py-3.9.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "Collecting jax>=0.3.15 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached jax-0.4.13-py3-none-any.whl\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting numpy<1.24,>=1.22 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached numpy-1.23.5-cp311-cp311-win_amd64.whl (14.6 MB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in e:\\tensorflow\\toxicity\\ss\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached protobuf-4.23.3-cp310-abi3-win_amd64.whl (422 kB)\n",
      "Requirement already satisfied: setuptools in e:\\tensorflow\\toxicity\\ss\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\tensorflow\\toxicity\\ss\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached wrapt-1.14.1-cp311-cp311-win_amd64.whl\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached grpcio-1.56.0-cp311-cp311-win_amd64.whl (4.2 MB)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\tensorflow\\toxicity\\ss\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.1.0-cp311-cp311-win_amd64.whl (470 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.40.0-cp311-cp311-win_amd64.whl (1.9 MB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.4-cp311-cp311-win_amd64.whl (55 kB)\n",
      "Collecting pillow>=6.2.0 (from matplotlib)\n",
      "  Downloading Pillow-10.0.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "                                              0.0/2.5 MB ? eta -:--:--\n",
      "     ---                                      0.2/2.5 MB 4.6 MB/s eta 0:00:01\n",
      "     -------                                  0.5/2.5 MB 4.7 MB/s eta 0:00:01\n",
      "     ---------                                0.6/2.5 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------                           0.9/2.5 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------                       1.2/2.5 MB 5.0 MB/s eta 0:00:01\n",
      "     -----------------------                  1.5/2.5 MB 5.3 MB/s eta 0:00:01\n",
      "     ----------------------------             1.8/2.5 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------        2.1/2.5 MB 5.6 MB/s eta 0:00:01\n",
      "     -------------------------------------    2.4/2.5 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 5.3 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.0-py3-none-any.whl (102 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting ml-dtypes>=0.1.0 (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl (938 kB)\n",
      "Collecting scipy>=1.7 (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached scipy-1.11.1-cp311-cp311-win_amd64.whl (44.0 MB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached google_auth-2.21.0-py2.py3-none-any.whl (182 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting urllib3<2.0 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.1.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\tensorflow\\toxicity\\ss\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\tensorflow\\toxicity\\ss\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.3)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: sklearn, pytz, libclang, flatbuffers, wrapt, wheel, werkzeug, urllib3, tzdata, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyparsing, pyasn1, protobuf, pillow, oauthlib, numpy, markdown, kiwisolver, keras, grpcio, google-pasta, gast, fonttools, cycler, charset-normalizer, certifi, cachetools, absl-py, scipy, rsa, requests, pyasn1-modules, pandas, opt-einsum, ml-dtypes, h5py, contourpy, astunparse, requests-oauthlib, matplotlib, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 certifi-2023.5.7 charset-normalizer-3.1.0 contourpy-1.1.0 cycler-0.11.0 flatbuffers-23.5.26 fonttools-4.40.0 gast-0.4.0 google-auth-2.21.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.56.0 h5py-3.9.0 jax-0.4.13 keras-2.12.0 kiwisolver-1.4.4 libclang-16.0.0 markdown-3.4.3 matplotlib-3.7.1 ml-dtypes-0.2.0 numpy-1.23.5 oauthlib-3.2.2 opt-einsum-3.3.0 pandas-2.0.3 pillow-10.0.0 protobuf-4.23.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 pyparsing-3.1.0 pytz-2023.3 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.11.1 sklearn-0.0.post5 tensorboard-2.12.3 tensorboard-data-server-0.7.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 werkzeug-2.3.6 wheel-0.40.0 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pandas matplotlib sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876e45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d4f9633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\\\tensorflow\\\\toxicity\\\\jigsaw-toxic-comment-classification-challenge\\\\train.csv\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "db023bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\r\\n\\r\\nThat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\r\\n\\r\\nUmm, theres no actual article ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\r\\nAnd ... I really don't think you understa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\r\\n\\r\\nThat...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\r\\n\\r\\nUmm, theres no actual article ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\r\\nAnd ... I really don't think you understa...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75924dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dce933ef",
   "metadata": {},
   "source": [
    "df.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd8ddcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"comment_text\"]\n",
    "y = df.iloc[:, 2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d173c093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0811450f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Explanation\\r\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
       "       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n",
       "       \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n",
       "       ...,\n",
       "       'Spitzer \\r\\n\\r\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.',\n",
       "       'And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.',\n",
       "       '\"\\r\\nAnd ... I really don\\'t think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3c63bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c67c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000\n",
    "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                               output_sequence_length=1800,\n",
    "                               output_mode='int')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "21fb2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "31a93cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorized_text = vectorizer(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bea4c94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
       "array([[  645,    76,     2, ...,     0,     0,     0],\n",
       "       [    1,    54,  2489, ...,     0,     0,     0],\n",
       "       [  425,   441,    70, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [32445,  7392,   383, ...,     0,     0,     0],\n",
       "       [    5,    12,   534, ...,     0,     0,     0],\n",
       "       [    5,     8,   130, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf505b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "data = data.cache()\n",
    "data = data.shuffle(160000)\n",
    "data = data.batch(16)\n",
    "data = data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0f35b5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 1800), dtype=tf.int64, name=None), TensorSpec(shape=(None, 6), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1952fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(int(len(data)*.7))\n",
    "val = data.skip(int(len(data)*.7)).take(int(len(data)*.7))\n",
    "test = data.skip(int(len(data)*.9)).take(int(len(data)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "87457f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1800)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.as_numpy_iterator().next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02a395e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, 1800), dtype=tf.int64, name=None), TensorSpec(shape=(None, 6), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae92e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0246a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import  LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8dbc4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_FEATURES+1, 32))\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "58e56d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,491,686\n",
      "Trainable params: 6,491,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9c43af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6061a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b59f5f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,491,686\n",
      "Trainable params: 6,491,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e370ce46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6981/6981 [==============================] - 9299s 1s/step - loss: 0.0632 - val_loss: 0.0475\n"
     ]
    }
   ],
   "source": [
    "# do train it for atleast 10 epochs for better results\n",
    "prediction = model.fit(train, epochs=1, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b822673f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[0.06323424726724625], [0.0475362204015255]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.history.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f8bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a356ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "53a34e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "x_true, y_true = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9f4f4457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5e8a99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "30693c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "rec = Recall()\n",
    "catacc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a870207c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "p = pre(y_true, y_pred)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9c04915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = rec(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "76df78a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.75>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "16e8dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cat = catacc(y_true, y_pred)\n",
    "print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a29d7cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = vectorizer('i will beat you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5bd6f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08205473, 0.000511  , 0.01070157, 0.00161695, 0.01920762,\n",
       "        0.00849122]], dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(comment,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8e392cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab786b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss",
   "language": "python",
   "name": "ss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
